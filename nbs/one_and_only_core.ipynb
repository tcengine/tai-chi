{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnpackAI Library Development Plan\n",
    "> What library should we be?\n",
    "This proposal, is more of a branding proposal, targeting people who's going to play with AI, from various back grounds.\n",
    "* That means, we're going to talk about how people view this library, how they think of ```pip install -Uqq unpackai``` like if I have dandroff recengtly and my mind just jump right into the headshoulders.\n",
    "* For ML, currently, the **jump** is about the following, this is not a throught marketing research, just quick examples from a deep learning practitioner:\n",
    "    * Try free structure quickly, do experiments: pytorch\n",
    "    * Goes to production, run model on edge devices, Tensorflow\n",
    "    * Play with GPU accelerated tensor calculation: Jax\n",
    "    * Play with tf but in simpler layer sense: Keras\n",
    "    * Transformer in clean code: Huggingface\n",
    "    * Visualize things with interactive features: Plotly\n",
    "    * Deploy model prototype: streamlit\n",
    "* Surely you think I fail to mention ```fastai```, this is where the **branding goes wrong**, fastai library is bounded tightly with the education. It's considered a good creation along side its famous course, after the education. Its product feature has many limitation: docs too brief, not supporting multi-device training, very limited numbers of callbacks went beyond Jeremy H's own teaching.\n",
    "* Most important of all, ```fastai``` isn't enjoyable to use, **it's just packing many things mentioned in the course**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we shouldn't be\n",
    "I know the course is life changing for me and I feel very grateful. But let's not be their library.\n",
    "\n",
    "### The pipeline wrapping plan\n",
    "It all started from a notebook, quite like a template notebook we have for the course. A notebook that achieves the data processing, model building, interpretation for a specific DL task.\n",
    "\n",
    "Then came the packaging part, we wrap **dozens of lines of codes**, which scares our kind students, into simple functions, or class.\n",
    "\n",
    "The wrapped functions are simple to use, to look at, it was executed in 1 line mostly. So friendly to our innocent students.\n",
    "\n",
    "This is what a python library is about, right? Wrap things into functions which can be further wraped into even less lines.\n",
    "\n",
    "It's nothing wrong about this approach at first. Some DL task, if need be, can be shrank into **less than 10 lines of codes.**\n",
    "* The 1st line load the data, \n",
    "* the 2nd line set how to transform data, \n",
    "* the 3rd line build/load the model, \n",
    "* the 4th line trained model.\n",
    "* the 5th line interpret the model in various ways\n",
    "\n",
    "Well the above do look like a decent **structure** to start with, then we pave out the tasks, different contributors take different tasks, can be developed in parallel, and we can have the agile/crum/kanban fun to track our progress!\n",
    "\n",
    "Even if we do this, we could build a useful product, no less.\n",
    "\n",
    "#### Bad side about pipeline wrapping plan\n",
    "So so many libraries are doing the same, from awesome people even. They usually end up to the following:\n",
    "* It's a mess of functions, among them many good functions but a mess. It ends up a branding disaster. (**There is no way to answer: what can you library do, in a slogan**)\n",
    "* A model zoo for a specific domain.\n",
    "* Wraping things up means less and less involvement from the user. The user will spend very little time play with the functions, and each function usually achieve very specific task. Actually I do believe there is a equilibrium like:\n",
    "$\\large{UserPlayHours = a * Task Transferability}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salvation plan is somehow simpler at how we perceive the library:\n",
    "* A library that allows you experiment AI/DL for various tasks\n",
    "\n",
    "**BUT!!!**\n",
    "* Many module with in the pipeline should be dropdown-list/checkbox **Choosable**.\n",
    "* The **level of detail** we let them to play and choose, is the **level of the difficulty** we want them to enjoy\n",
    "\n",
    "### What is level of detail ?\n",
    "Level of details is the level of fuss we want user to focus on, this is the exact part fastai library got **WRONG**, which will explain most of our struggle so far:\n",
    "* It offers smooth/ easy pipelines, for newbies and business people even.\n",
    "* Any amount of reconfigure, is usually way too complicated for such audience\n",
    "* There is a **GAP** between the 2 points above, hence no room for playing\n",
    "\n",
    "#### Keras Example \n",
    "I started my AI journey with Keras, and I love keras by that time, because:\n",
    "* Keras plays with **layers**(eg. Linear, Convolution), its most strenth is at astracting details beneath this level, and let users play with layers. \n",
    "* I spent lots of time, having fun playing with layers\n",
    "* Aside from the things I have to redesign layer, I can deploy almost all kinds of models mentioned in any DL paper (ð‘ˆð‘ ð‘’ð‘Ÿð‘ƒð‘™ð‘Žð‘¦ð»ð‘œð‘¢ð‘Ÿð‘ =ð‘Žâˆ—ð‘‡ð‘Žð‘ ð‘˜ð‘‡ð‘Ÿð‘Žð‘›ð‘ ð‘“ð‘’ð‘Ÿð‘Žð‘ð‘–ð‘™ð‘–ð‘¡ð‘¦)\n",
    "\n",
    "#### Pytorch lightning example\n",
    "Well I moved on to the career team. I have to deal with layer level, I have to deal with different data/forward pipeline. PL is a good library because:\n",
    "* It allows me play with the things I mentioned, but save my energy on things like looping, logging, multidevice training detail etc.\n",
    "* If you see a training notebook built by PL, you'll see very little lines around training template.\n",
    "* You'll find about a lots of lines on the specifications you intend to be different.\n",
    "\n",
    ">The branding image of the examples are simple:\n",
    "* Keras: play TensorFlow in a concept of layers\n",
    "* Pytorch-Lightning: writting less template code\n",
    "\n",
    "#### Unpackai Example\n",
    "For our lib, I intend for them to focus on, exactly the same range of things we want people to learn:\n",
    "* choose the columns they intend to use, in what way\n",
    "* choose the data transformations\n",
    "* choose the loss, the model structure to use (not keras.layer, not nn.module)\n",
    "* hit run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of such example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual\n",
    "from forgebox.imports import *\n",
    "from forgebox.category import Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path(os.environ['HOME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip data download here, it's download, we're not going to reinvent brilliant stuff around download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAR_DATASET = HOME/\"Downloads\"/\"bear_dataset\"\n",
    "BEAR_DATASET = \"/GCI/data/bear_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Everything starts with dataframe\n",
    "\n",
    "For fastai, everything starts from list, an ItemList to be specific. **ImageList** and **TextList** is [**ItemList**](https://fastai1.fast.ai/tutorial.itemlist.html) with some slight enhanced feature.```[ðŸ§‚, ðŸ“, ðŸ·, ðŸ»]```\n",
    "\n",
    "For the clarity of education, or for simplecity as ultimate form of beauty, we use [**DataFrame**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) as starting point, ItemList in table format. In this way, every dataset has the same starting point, even the tabular data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_creator_image_folder(path: Path):\n",
    "    path = Path(path)\n",
    "    files = list(path.rglob(\"*.jpg\"))\n",
    "    files.extend(path.rglob(\"*.JPG\"))\n",
    "    files.extend(path.rglob(\"*.jpeg\"))\n",
    "    files.extend(path.rglob(\"*.JPEG\"))\n",
    "    files.extend(path.rglob(\"*.png\"))\n",
    "    files.extend(path.rglob(\"*.PNG\"))\n",
    "    return pd.DataFrame({\"path\":files}).sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich columns (feature transformation, label extraction)\n",
    "After this step, there will only be **MORE** column âž•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase/ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable, Any, Tuple\n",
    "from torchvision import transforms as tfm\n",
    "from PIL import Image\n",
    "from forgebox.html import DOM\n",
    "from ipywidgets import VBox, HBox, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import (\n",
    "    Text, Textarea, IntSlider, FloatSlider, SelectMultiple, Dropdown, Checkbox,\n",
    "    Layout, Button\n",
    ")\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase:\n",
    "    \"\"\"\n",
    "    A configuration management mechanism\n",
    "    \"\"\"\n",
    "    is_phase = True\n",
    "    def __init__(self, **kwargs):\n",
    "        self.config = dict()\n",
    "        self.config.update(kwargs)\n",
    "        \n",
    "    def __setitem__(self, k, v):\n",
    "        self.config[k] = v\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        return self.config[k]\n",
    "    \n",
    "    def __contains__(self, k):\n",
    "        return k in self.config\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.get_data(self.config)\n",
    "    \n",
    "    def get_data(self, raw):\n",
    "        \"\"\"\n",
    "        Reconstruct back to dict or list or value format\n",
    "        \"\"\"\n",
    "        if hasattr(raw,\"is_phase\"):\n",
    "            return raw.get_data(raw.config)\n",
    "        if type(raw) == list:\n",
    "            raw = list(self.get_data(i) for i in raw)\n",
    "            return raw\n",
    "        if type(raw) == dict:\n",
    "            for k, v in raw.items():\n",
    "                raw[k] = self.get_data(v)\n",
    "            return raw\n",
    "        return raw\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self(), indent=2)\n",
    "    \n",
    "    def __repr__(self,):\n",
    "        return f\"Phase:{self}\"\n",
    "    \n",
    "\n",
    "class EnrichPhase(Phase):\n",
    "    def __init__(self, *steps):\n",
    "        super().__init__()\n",
    "        self.config['steps'] = []\n",
    "        for step in steps:\n",
    "            checked = self.check_step(step)\n",
    "            if checked:\n",
    "                self.config['steps'].append(checked)\n",
    "                \n",
    "    def new_step(self, process, dst:str, src: str=None):\n",
    "        self.config['steps'].append({\n",
    "            \"process\":process,\n",
    "            \"src\":src,\n",
    "            \"dst\":dst\n",
    "        })\n",
    "    \n",
    "    def check_step(self,step):\n",
    "        return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreOrLess(VBox):\n",
    "    \"\"\"\n",
    "    Interactive list\n",
    "    You can add item to the list\n",
    "    Each added item has a remove button to remove such item\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list: List[Any] = []):\n",
    "        super().__init__([])\n",
    "        for data in data_list:\n",
    "            self+data\n",
    "\n",
    "    def create_line(self, data):\n",
    "        children = list(self.children)\n",
    "        children.append(self.new_line(data))\n",
    "        self.children = children\n",
    "\n",
    "    @staticmethod\n",
    "    def data_to_dom(data):\n",
    "        return HTML(json.dumps(data))\n",
    "\n",
    "    def new_line(self, data) -> HBox:\n",
    "        del_btn = Button(description=\"Remove\", icon=\"trash\")\n",
    "        del_btn.button_style = 'danger'\n",
    "        hbox = HBox([del_btn, self.data_to_dom(data)])\n",
    "        hbox.data = data\n",
    "\n",
    "        def remove_hbox():\n",
    "            children = list(self.children)\n",
    "            for i, c in enumerate(children):\n",
    "                if id(c) == id(hbox):\n",
    "                    children.remove(c)\n",
    "            self.children = children\n",
    "        del_btn.click = remove_hbox\n",
    "        return hbox\n",
    "\n",
    "    def __add__(self, data):\n",
    "        self.create_line(data)\n",
    "        return self\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Return the data of this list\n",
    "        \"\"\"\n",
    "        return list(x.data for x in self.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = MoreOrLess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b706a74b5d4d6ab8bb0ec562a803f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess(children=(HBox(children=(Button(button_style='danger', description='Remove', icon='trash', style=Buâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mol+{\"hello\":\"yes\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### typings for interactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveTyping:\n",
    "    \"\"\"\n",
    "    Typing for interactive details\n",
    "    self.__call__() will create widgets directly\n",
    "    \"\"\"\n",
    "    name = \"anything\"\n",
    "    is_typing = True\n",
    "\n",
    "    def solid(self, default) -> None:\n",
    "        \"\"\"\n",
    "        Reset default value\n",
    "        \"\"\"\n",
    "        if default is not None:\n",
    "            self.default = default\n",
    "\n",
    "\n",
    "class INT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = 0, max_: int = 10, step: int = 1, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"int[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return IntSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class BOOL(InteractiveTyping):\n",
    "    def __init__(self, name:str=\"\", default: bool = True,):\n",
    "        self.default = default\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"bool={self.default}\"\n",
    "\n",
    "    def __call__(self, default: bool = None) -> Checkbox:\n",
    "        self.solid(default)\n",
    "        return Checkbox(value=self.default, description=self.name)\n",
    "\n",
    "\n",
    "class FLOAT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = -1., max_: int = 1., step: int = .01, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 0.01\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"float[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return FloatSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class STR(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    String object\n",
    "    will create text or textarea\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, default: str = None, use_area: bool = False):\n",
    "        \"\"\"\n",
    "        use_area: do we use Textarea, if False,we use Text\n",
    "        \"\"\"\n",
    "        self.default = \"\" if default is None else default\n",
    "        self.use_area = use_area\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"str='{self.default}'\"\n",
    "\n",
    "    def __call__(self, default: str = None):\n",
    "        self.solid(default)\n",
    "        if self.use_area:\n",
    "            return Textarea(value=self.default, layout=Layout(width=\"80%\"))\n",
    "        return Text(value=self.default)\n",
    "\n",
    "\n",
    "class LIST(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    dropdown list type or multiselection type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, options: List[Any] = [], default: Any = None, multi: bool = False):\n",
    "        \"\"\"\n",
    "        if multi: default should be iterable\n",
    "        else: default should be one of the option\n",
    "        \"\"\"\n",
    "        self.options = options\n",
    "        self.default = default\n",
    "        self.multi = multi\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.multi:\n",
    "            size = f\"[0-{self.default}]/{len(self.options)}\"\n",
    "        else:\n",
    "            size = f\"1/{len(self.options)}\"\n",
    "        return f\"list,{size}\"\n",
    "\n",
    "    def __call__(self, default: Any = None):\n",
    "        self.solid(default)\n",
    "        if self.multi:\n",
    "            inter = SelectMultiple(options=self.options)\n",
    "        else:\n",
    "            inter = Dropdown(options=self.options)\n",
    "\n",
    "        if self.default is not None:\n",
    "            # if multi: default should be iterable\n",
    "            # else: default should be one of the option\n",
    "            inter.value = self.default\n",
    "        return inter\n",
    "\n",
    "class InteractiveAnnotations:\n",
    "    \"\"\"\n",
    "    Build interactive based on the info of function's ```__annotations__```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, func: Callable,\n",
    "        icon: str = \"rocket\",\n",
    "        description: str = 'Run',\n",
    "        button_style='primary'\n",
    "    ):\n",
    "        self.func = func\n",
    "        self.icon = icon\n",
    "        self.button_style = button_style\n",
    "        self.description = description\n",
    "        self.build_vbox(func)\n",
    "\n",
    "    @classmethod\n",
    "    def on(\n",
    "        cls,\n",
    "        callback: Callable,\n",
    "        icon: str = 'rocket',\n",
    "        description: str = 'Run',\n",
    "        button_style: str = 'primary'\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        Use this class as a decorator\n",
    "        @InteractiveAnnotation.on(callback)\n",
    "        def target_func(a:STR(), b:INT()=1):\n",
    "            ...\n",
    "        \"\"\"\n",
    "        def decorator(func: Callable):\n",
    "            obj = cls(\n",
    "                func,\n",
    "                icon=icon,\n",
    "                description=description,\n",
    "                button_style=button_style\n",
    "            )\n",
    "            display(obj.vbox)\n",
    "            obj.register_callback(callback=callback)\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "    def build_vbox(self, func: Callable):\n",
    "        row_list = []\n",
    "        self.fields = dict()\n",
    "        for k, v in func.__annotations__.items():\n",
    "            if hasattr(v, \"is_typing\") == False:\n",
    "                continue\n",
    "            widget = v()\n",
    "            widget.description = k\n",
    "            row_list.append(widget)\n",
    "            self.fields.update({k: widget})\n",
    "\n",
    "        # final button\n",
    "        self.final_btn = Button(\n",
    "            description=self.description,\n",
    "            icon=self.icon,\n",
    "        )\n",
    "        self.final_btn.button_style = self.button_style\n",
    "        row_list.append(self.final_btn)\n",
    "\n",
    "        # create interactive\n",
    "        self.vbox = VBox(row_list)\n",
    "        return self.vbox\n",
    "\n",
    "    def register_callback(\n",
    "        self,\n",
    "        callback: Callable\n",
    "    ) -> None:\n",
    "        def run_callback():\n",
    "            kwargs = self()\n",
    "            callback(kwargs)\n",
    "        self.final_btn.click = run_callback\n",
    "\n",
    "    def __call__(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        extract interactive data values\n",
    "        \"\"\"\n",
    "        rt = dict()\n",
    "        for k, widget in self.fields.items():\n",
    "            rt.update({k: widget.get_interact_value()})\n",
    "        return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ef35ea6504fd1a118b4e9ab52f4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='a'), IntSlider(value=1, description='b', max=10), Button(button_styâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_stuff(kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "@InteractiveAnnotations.on(print_stuff, \"flask\", \"test\", button_style=\"warning\")\n",
    "def some_func(e, a:STR(), b:INT()=2, d=3):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9039124a81f4fa5aa8fc09e5874f8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='RGB')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STR('RGB')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enrich:\n",
    "    \"\"\"\n",
    "    Enrich Base Class\n",
    "    Some default attributes\n",
    "    - is_enrich = True\n",
    "    - typing = None # output typing\n",
    "    - multi_cols = False # use multi-column as input\n",
    "    - prefer = None\n",
    "    - lazy = False  # shall we execute enrichment only through the iteration\n",
    "    - src = None # source column\n",
    "    \"\"\"\n",
    "    is_enrich = True\n",
    "    typing = None # output typing\n",
    "    multi_cols = False # use multi-column as input\n",
    "    prefer = None\n",
    "    lazy = False  # shall we execute enrichment only through the iteration\n",
    "    src = None # source column\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return row\n",
    "    \n",
    "    def rowing(self, row):\n",
    "        if self.multi_cols:\n",
    "            return self(row)\n",
    "        else:\n",
    "            return self(row[self.src])\n",
    "\n",
    "\n",
    "class EnrichImage(Enrich):\n",
    "    \"\"\"\n",
    "    Create Image column from image path column\n",
    "    \"\"\"\n",
    "    prefer = \"QuantifyImage\"\n",
    "    typing = Image\n",
    "    lazy = True\n",
    "    \n",
    "\n",
    "    def __init__(\n",
    "        self, convert: STR(\"RGB\") = \"RGB\",\n",
    "        size: LIST(options=[28, 128, 224, 256, 512], default=224) = 224,\n",
    "    ):\n",
    "        self.convert = convert\n",
    "        self.size = size\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[Image:{self.size}]\"\n",
    "\n",
    "    def __call__(self, x):\n",
    "        img = Image.open(x).convert(self.convert)\n",
    "        img = img.resize((self.size, self.size))\n",
    "        return img\n",
    "\n",
    "\n",
    "class ParentAsLabel(Enrich):\n",
    "    typing = str\n",
    "    prefer = \"QuantifyCategory\"\n",
    "    def __call__(self, path: Path,) -> str:\n",
    "        \"\"\"\n",
    "        Use parent folder name as label\n",
    "        \"\"\"\n",
    "        return Path(path).parent.name\n",
    "    \n",
    "ENRICHMENTS = dict(\n",
    "    EnrichImage=EnrichImage,\n",
    "    ParentAsLabel=ParentAsLabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kwargs(kwargs):\n",
    "    print(kwargs)\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def reconfig_manual_interact(\n",
    "    widget,\n",
    "    description: str = \"Create\",\n",
    "    button_style: str = \"primary\",\n",
    "    icon: str = \"plus\"\n",
    ") -> Button:\n",
    "    \"\"\"\n",
    "    reconfigure the button of interactive features\n",
    "    \"\"\"\n",
    "    btn = None\n",
    "    for w in widget.children:\n",
    "        if type(w) == Button:\n",
    "            btn = w\n",
    "            break\n",
    "    btn.description = description\n",
    "    btn.button_style = button_style\n",
    "    btn.icon = icon\n",
    "    return btn\n",
    "\n",
    "\n",
    "def interact_intercept(\n",
    "    func:Callable,\n",
    "    result_cb: Callable = print_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize a class with interactive features\n",
    "    \"\"\"\n",
    "    annotations = func.__annotations__\n",
    "    defaults = func.__defaults__\n",
    "    kwargs = dict()\n",
    "    if defaults is not None:\n",
    "        for (k, typing), default in zip(annotations.items(), defaults):\n",
    "            kwargs.update({k: typing(default)})\n",
    "    obj = dict()\n",
    "\n",
    "    def fillin_init(**kwargs):\n",
    "        obj.update({\n",
    "            \"kwargs\": kwargs,\n",
    "        })\n",
    "    f = interact_manual(fillin_init, **kwargs)\n",
    "\n",
    "    btn = reconfig_manual_interact(f.widget)\n",
    "\n",
    "    if btn is not None:\n",
    "        original = btn.click\n",
    "\n",
    "        def new_click_event():\n",
    "            original()\n",
    "            return result_cb(obj['kwargs'])\n",
    "        btn.click = new_click_event\n",
    "\n",
    "    return obj, f\n",
    "\n",
    "def init_interact(cls, result_cb: Callable = print_kwargs):\n",
    "    return interact_intercept(cls.__init__, result_cb=result_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142610f8b37f4bdaac27ac1573297c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='RGB', description='convert'), Dropdown(description='size', index=2, options=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj,f = init_interact(EnrichImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = Phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000026.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000135.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000062.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000062.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000044.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000099.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000167.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000047.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000045.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path\n",
       "0     /GCI/data/bear_dataset/teddys/00000026.jpg\n",
       "1      /GCI/data/bear_dataset/black/00000135.jpg\n",
       "2    /GCI/data/bear_dataset/teddys/00000062.jpeg\n",
       "3      /GCI/data/bear_dataset/black/00000062.jpg\n",
       "4      /GCI/data/bear_dataset/black/00000044.jpg\n",
       "..                                           ...\n",
       "517  /GCI/data/bear_dataset/grizzly/00000011.jpg\n",
       "518    /GCI/data/bear_dataset/black/00000099.jpg\n",
       "519  /GCI/data/bear_dataset/grizzly/00000167.jpg\n",
       "520  /GCI/data/bear_dataset/grizzly/00000047.jpg\n",
       "521    /GCI/data/bear_dataset/black/00000045.jpg\n",
       "\n",
       "[522 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bear_df = df_creator_image_folder(BEAR_DATASET)\n",
    "\n",
    "bear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_enrich(df):\n",
    "    global phase\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "\n",
    "    def setting_col():\n",
    "        enrich_data_list = phase['enrich'] if 'enrich' in phase else []\n",
    "        enrich_box = MoreOrLess(enrich_data_list)\n",
    "        display(enrich_box)\n",
    "\n",
    "        \n",
    "        def set_enrich_(src=[\"[all_columns]\", ]+list(df.columns)):\n",
    "            DOM(f\"Setting up column enrich: {src}\", \"h4\")()\n",
    "            if src == \"[all_columns]\":\n",
    "                display(df.head(3))\n",
    "            else:\n",
    "                display(df[[src, ]].head(3))\n",
    "\n",
    "            def choose_enrich(dst=\"\", enrich=ENRICHMENTS):\n",
    "                DOM(f\"Source: {src}, Destination: {dst}, for {enrich.__name__}\", \"h4\")(\n",
    "                )\n",
    "                DOM(f\"{enrich.__doc__}\", \"quote\")()\n",
    "\n",
    "                def result_callback(kwargs):\n",
    "                    extra = {\"src\": src, \"dst\": dst,\n",
    "                                \"kwargs\": kwargs, \"enrich\": enrich.__name__}\n",
    "                    enrich_box+extra\n",
    "                    phase['enrich'] = enrich_box.get_data()\n",
    "                obj, decoed_func = init_interact(enrich, result_callback)\n",
    "            choose_enrich_widget = interact_manual(choose_enrich).widget\n",
    "            reconfig_manual_interact(\n",
    "                choose_enrich_widget,\n",
    "                description=\"Choose\", button_style='warning')\n",
    "        set_enrich_widget = interact_manual(set_enrich_).widget\n",
    "        reconfig_manual_interact(set_enrich_widget, button_style='warning')\n",
    "    setting_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>522 rows of data, example table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000144.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000096.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000109.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000069.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path\n",
       "23     /GCI/data/bear_dataset/black/00000144.jpg\n",
       "399   /GCI/data/bear_dataset/teddys/00000096.jpg\n",
       "299    /GCI/data/bear_dataset/black/00000109.jpg\n",
       "28   /GCI/data/bear_dataset/grizzly/00000094.jpg\n",
       "335    /GCI/data/bear_dataset/black/00000069.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85df689a8dc54b12937d7e3cf4d95dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111b0415fc80443b8f20a7e98af879de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d9cdae8dcc4deca3f01d399ec36b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='src', options=('[all_columns]', 'path'), value='[all_columns]'), Bâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_enrich(bear_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"enrich\": [\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"image\",\n",
       "      \"kwargs\": {\n",
       "        \"convert\": \"RGB\",\n",
       "        \"size\": 224\n",
       "      },\n",
       "      \"enrich\": \"EnrichImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"label\",\n",
       "      \"kwargs\": {},\n",
       "      \"enrich\": \"ParentAsLabel\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_enrich(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    for en_conf in tqdm(phase[\"enrich\"], leave=False):\n",
    "        enrich_name = en_conf['enrich']\n",
    "        enrich_cls = ENRICHMENTS[enrich_name]\n",
    "        kwargs = en_conf['kwargs']\n",
    "        src = en_conf['src']\n",
    "        dst = en_conf['dst']\n",
    "        # The class with lazy loading, will only \n",
    "        # call the class only if necessary\n",
    "        if enrich_cls.lazy:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            obj.src = src\n",
    "            df[dst] = obj\n",
    "        # The class without lazy loading\n",
    "        # create the column now\n",
    "        else:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            if src==\"[all_columns]\":\n",
    "                df[dst] = df.apply(obj, axis=1)\n",
    "            else:\n",
    "                df[dst] = df[src].apply(obj)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000026.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>teddys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000135.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000062.jpeg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>teddys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000062.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000044.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000011.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>grizzly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000099.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000167.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>grizzly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000047.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>grizzly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000045.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path        image    label\n",
       "0     /GCI/data/bear_dataset/teddys/00000026.jpg  [Image:224]   teddys\n",
       "1      /GCI/data/bear_dataset/black/00000135.jpg  [Image:224]    black\n",
       "2    /GCI/data/bear_dataset/teddys/00000062.jpeg  [Image:224]   teddys\n",
       "3      /GCI/data/bear_dataset/black/00000062.jpg  [Image:224]    black\n",
       "4      /GCI/data/bear_dataset/black/00000044.jpg  [Image:224]    black\n",
       "..                                           ...          ...      ...\n",
       "517  /GCI/data/bear_dataset/grizzly/00000011.jpg  [Image:224]  grizzly\n",
       "518    /GCI/data/bear_dataset/black/00000099.jpg  [Image:224]    black\n",
       "519  /GCI/data/bear_dataset/grizzly/00000167.jpg  [Image:224]  grizzly\n",
       "520  /GCI/data/bear_dataset/grizzly/00000047.jpg  [Image:224]  grizzly\n",
       "521    /GCI/data/bear_dataset/black/00000045.jpg  [Image:224]    black\n",
       "\n",
       "[522 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_enrich(bear_df, phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify: Choose columns as X and Y, put them into number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIZE_DIMENSION:\n",
    "    pass\n",
    "\n",
    "class BATCH_SIZE(SIZE_DIMENSION):\n",
    "    def __repr__(self): return f\"BATCH_SIZE\"\n",
    "\n",
    "class SEQUENCE_SIZE(SIZE_DIMENSION):\n",
    "    pass\n",
    "\n",
    "class IMAGE_SIZE(SIZE_DIMENSION):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Quantify:\n",
    "    is_quantify = True\n",
    "    \"\"\"\n",
    "    # From all things to number\n",
    "    The AI model does not understand anything, say, picture, text\n",
    "    Unless you transform it to integer and float tensors\n",
    "\n",
    "    Quantify and its subclass controls the\n",
    "        numericalization / collation of the data pipeline\n",
    "    The base class of quantify does: NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, list_of_items):\n",
    "        return list(list_of_items)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        A function to let the data processing\n",
    "        adapt to the data column\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __hash__(self,):\n",
    "        if hasattr(self, \"name\"):\n",
    "            return self.name\n",
    "        else:\n",
    "            return self.__class__.__name__\n",
    "\n",
    "\n",
    "class QuantifyImage(Quantify):\n",
    "    \"\"\"\n",
    "    Transform PIL.Image to tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mean_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "        std_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "    ):\n",
    "        if type(mean_) == str:\n",
    "            if mean_ == \"imagenet\":\n",
    "                mean_ = [0.485, 0.456, 0.406]\n",
    "            elif mean_ == \"0.5 x 3\":\n",
    "                mean_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Mean configuration: {mean_} not valid\")\n",
    "\n",
    "        if type(std_) == str:\n",
    "            if std_ == \"imagenet\":\n",
    "                std_ = [0.229, 0.224, 0.225]\n",
    "            elif std_ == \"0.5 x 3\":\n",
    "                std_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Standard Variation configuration: {std_} not valid\")\n",
    "\n",
    "        self.transform = tfm.Compose([\n",
    "            tfm.ToTensor(),\n",
    "            tfm.Normalize(mean=mean_, std=std_),\n",
    "        ])\n",
    "        \n",
    "        self.shape = (BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Image to tensors:{self.transform}\"\n",
    "\n",
    "    def __call__(self, list_of_image):\n",
    "        return torch.stack(list(\n",
    "            self.transform(img) for img in list_of_image))\n",
    "\n",
    "\n",
    "class QuantifyText(Quantify):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained: STR(default=\"bert-base-cased\") = \"bert-base-cased\",\n",
    "        max_length: INT(default=512, min_=12, max_=1024, step=4) = 512,\n",
    "        padding: LIST(options=[\n",
    "            \"do_not_pad\",\n",
    "            \"max_length\",\n",
    "            \"longest\"], default=\"max_length\") = \"max_length\",\n",
    "        return_token_type_ids: BOOL(name=\"Token Type IDs\", default=True) = True,\n",
    "        return_attention_mask: BOOL(name=\"Attention Mask\", default=True) = True,\n",
    "        return_offsets_mapping: BOOL(name=\"Offset Mapping\", default=False) = False,\n",
    "    ):\n",
    "        self.pretrained = pretrained\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.return_token_type_ids = return_token_type_ids\n",
    "        self.return_attention_mask = return_attention_mask\n",
    "        self.return_offsets_mapping = return_offsets_mapping\n",
    "        self.truncation = True\n",
    "        self.return_tensors = 'pt'\n",
    "        self.shape = (BATCH, SEQUENCE_SIZE)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        Initialize tokenizer\n",
    "        \"\"\"\n",
    "        from transformers import AutoTokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.pretrained, use_fast=True)\n",
    "\n",
    "    def __call__(self, list_of_text: List[str]):\n",
    "        list_of_text = list(list_of_text)\n",
    "        return self.tokenizer(\n",
    "            list_of_text,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            truncation=self.truncation,\n",
    "            return_token_type_ids=self.return_token_type_ids,\n",
    "            return_attention_mask=self.return_attention_mask,\n",
    "            return_tensors=self.return_tensors,\n",
    "            return_offsets_mapping=self.return_offsets_mapping,\n",
    "        )\n",
    "\n",
    "\n",
    "class QuantifyCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Transform single categorical data to index numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_frequency: INT(min_=1, max_=20, default=1) = 1,\n",
    "    ):\n",
    "        self.min_frequency = min_frequency\n",
    "\n",
    "    def adapt(self, column):\n",
    "        # category statistics\n",
    "        value_counts = pd.DataFrame(column.value_counts())\n",
    "\n",
    "        # if minimun freq is 1\n",
    "        # very category occured should be accounted for\n",
    "        # hence no missing token padding is required\n",
    "        if self.min_frequency < 2:\n",
    "            self.category = Category(\n",
    "                arr=np.array(value_counts.index),\n",
    "                pad_mst=False)\n",
    "\n",
    "        # we need missing token\n",
    "        # for category's frequency < self.min_frequency\n",
    "        else:\n",
    "            categories = np.array(\n",
    "                list(value_counts.index[\n",
    "                    value_counts.values.reshape(-1) > self.min_frequency]))\n",
    "            self.category = Category(arr=categories, pad_mst=True)\n",
    "\n",
    "        self.shape = (BATCH_SIZE, len(self.category))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Category:{self.category}\"\n",
    "\n",
    "    def __call__(self, list_of_strings):\n",
    "        return torch.LongTensor(self.category.c2i[np.array(list_of_strings)])\n",
    "\n",
    "\n",
    "class QuantifyNum(Quantify):\n",
    "    \"\"\"\n",
    "    Quantify contineous data, like float numbers\n",
    "    The only process is normalization on the entire population\n",
    "    \"\"\"\n",
    "    shape = (BATCH_SIZE, 1)\n",
    "    def adapt(self, column):\n",
    "        self.mean_ = column.mean()\n",
    "        self.std_ = column.std()\n",
    "\n",
    "    def __call__(self, list_of_num):\n",
    "        return (torch.FloatTensor(list_of_num)[None,:]-self.mean_)/self.std_\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*self.std_+self.mean_\n",
    "\n",
    "\n",
    "class QuantifyMultiCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Turn Multi-categorical data to n_hot encoding numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, col_name: str):\n",
    "        self.col_name = col_name\n",
    "\n",
    "\n",
    "QUANTIFY = dict(\n",
    "    Quantify=Quantify,\n",
    "    QuantifyImage=QuantifyImage,\n",
    "    QuantifyCategory=QuantifyCategory,\n",
    "    QuantifyMultiCategory=QuantifyMultiCategory,\n",
    "    QuantifyText=QuantifyText,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A pytorch dataset working under our environment\n",
    "    \"\"\"\n",
    "    def __init__(self, df, columns: List[Any] = None):\n",
    "        self.df = df\n",
    "        self.columns = list(df.columns) if columns is None else columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        row = dict(self.df.loc[idx])\n",
    "        rt = dict()\n",
    "        for col in self.columns:\n",
    "            v = row[col]\n",
    "            if hasattr(v, \"is_enrich\"):\n",
    "                rt[col] = v.rowing(row)\n",
    "            else:\n",
    "                rt[col] = v\n",
    "        return rt\n",
    "    \n",
    "    def split(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1\n",
    "    ) -> Tuple[Any]:\n",
    "        cls = self.__class__\n",
    "        slicing = (np.random.rand(len(self)) < valid_ratio)\n",
    "        return (\n",
    "            cls(self.df[slicing].reset_index(drop=True), self.columns),\n",
    "            cls(self.df[~slicing].reset_index(drop=True), self.columns)\n",
    "        )\n",
    "\n",
    "    def dataloader(\n",
    "        self,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = False,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):\n",
    "        return DataLoader(\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.html import list_group_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('/GCI/data/bear_dataset/black/00000135.jpg'),\n",
       " 'image': <PIL.Image.Image image mode=RGB size=224x224 at 0x7FC1D8579C50>,\n",
       " 'label': 'black'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TaiChiDataset(bear_df)\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_xy(df):\n",
    "    global phase\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "    DOM(\"Please Choose Column\", \"h3\")()\n",
    "    DOM(\"The AI model will try to guess the Y with the input X\", \"div\", {\"style\":\"color:#666699\"})()\n",
    "    \n",
    "    task = 'quantify'\n",
    "    # enrich by columns\n",
    "    if \"enrich\" in phase:\n",
    "        by_destination = dict((en['dst'], en) for en in phase['enrich'])\n",
    "    else:\n",
    "        by_destination = dict()\n",
    "    \n",
    "    data_list = phase[task] if task in phase else []\n",
    "    mol_box = MoreOrLess(data_list)\n",
    "    display(mol_box)\n",
    "\n",
    "    @interact_manual\n",
    "    def set_quantify_(src=list(df.columns), use_for = [\"As X\", \"As Y\"]):\n",
    "        DOM(f\"Quantify Column: {src} {use_for}\", \"h4\")()\n",
    "        display(df[[src, ]].head(3))\n",
    "        \n",
    "        quantify_dropdown = Dropdown(options=list(QUANTIFY.keys()))\n",
    "        \n",
    "        # check the hint from last step\n",
    "        prefer = None\n",
    "        if src in by_destination:\n",
    "            col_config = by_destination[src]\n",
    "            cls = ENRICHMENTS[col_config['enrich']]\n",
    "\n",
    "            # In case the enrich layer has the preference\n",
    "            if hasattr(cls, \"prefer\"):\n",
    "                prefer = cls.prefer\n",
    "                \n",
    "                # set default value to drop down value,\n",
    "                # if the the previous hint suggest so\n",
    "                quantify_dropdown.value = prefer\n",
    "                DOM(f\"Prefered quantifying:\\t{cls.prefer}\", \"h4\")()\n",
    "            if hasattr(cls, \"typing\"):\n",
    "                DOM(f\"Output data type:\\t{cls.typing}\", \"h4\")()\n",
    "        \n",
    "        @interact_manual\n",
    "        def choose_quantify(quantify = quantify_dropdown):\n",
    "            cls = QUANTIFY[quantify]\n",
    "            def result_callback(kwargs):\n",
    "                extra = {\"src\": src, \"x\":(use_for==\"As X\"),\n",
    "                        \"kwargs\": kwargs, \"quantify\": cls.__name__}\n",
    "                mol_box+extra\n",
    "                phase['quantify'] = mol_box.get_data()\n",
    "                \n",
    "            obj, decoded = init_interact(cls, result_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>522 rows of data, example table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000182.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>teddys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000106.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>/GCI/data/bear_dataset/grizzly/00000049.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>grizzly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>/GCI/data/bear_dataset/teddys/00000092.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>teddys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>/GCI/data/bear_dataset/black/00000177.jpg</td>\n",
       "      <td>[Image:224]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path        image    label\n",
       "55    /GCI/data/bear_dataset/teddys/00000182.jpg  [Image:224]   teddys\n",
       "268    /GCI/data/bear_dataset/black/00000106.jpg  [Image:224]    black\n",
       "269  /GCI/data/bear_dataset/grizzly/00000049.jpg  [Image:224]  grizzly\n",
       "54    /GCI/data/bear_dataset/teddys/00000092.jpg  [Image:224]   teddys\n",
       "116    /GCI/data/bear_dataset/black/00000177.jpg  [Image:224]    black"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bd411adb6d4ad3a5ad294fb71a5397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Please Choose Column</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"color:#666699\">The AI model will try to guess the Y with the input X</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7667ef7d1f4ab09d734d8cf36560ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a19f83011e044dcaf254b54bb05fd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='src', options=('path', 'image', 'label'), value='path'), Dropdown(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choose_xy(bear_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"enrich\": [\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"image\",\n",
       "      \"kwargs\": {\n",
       "        \"convert\": \"RGB\",\n",
       "        \"size\": 224\n",
       "      },\n",
       "      \"enrich\": \"EnrichImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"label\",\n",
       "      \"kwargs\": {},\n",
       "      \"enrich\": \"ParentAsLabel\"\n",
       "    }\n",
       "  ],\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"image\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"mean_\": \"imagenet\",\n",
       "        \"std_\": \"imagenet\"\n",
       "      },\n",
       "      \"quantify\": \"QuantifyImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"label\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1\n",
       "      },\n",
       "      \"quantify\": \"QuantifyCategory\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_quantify(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    # existance check\n",
    "    if 'quantify' not in phase:\n",
    "        raise KeyError(f\"No quantify stepset\")\n",
    "    \n",
    "    qdict = dict()\n",
    "    for i, qconf in tqdm(enumerate(phase['quantify']), leave = False):\n",
    "        qname = qconf['quantify']\n",
    "        kwargs = qconf['kwargs']\n",
    "        src = qconf['src']\n",
    "        x = qconf['x']\n",
    "        \n",
    "        cls = QUANTIFY[qname]\n",
    "        qobj = cls(**kwargs)\n",
    "        qobj.src = src\n",
    "        qobj.is_x = x\n",
    "        qobj.adapt(df[src])\n",
    "        qdict.update({src:qobj})\n",
    "    return qdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qdict = execute_quantify(bear_df, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': Quantify Image to tensors:Compose(\n",
       "     ToTensor()\n",
       "     Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       " ),\n",
       " 'label': Quantify Category:Category Manager with 3}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create collate with dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiCollate:\n",
    "    \"\"\"\n",
    "    Universal all power full collate function\n",
    "    \"\"\"\n",
    "    def __init__(self, quantify_dict):\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "    def make_df(self, batch):\n",
    "        return pd.DataFrame(list(batch))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.quantify_dict)\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        batch_df = self.make_df(batch)\n",
    "        rt = dict()\n",
    "        for src,qobj in self.quantify_dict.items():\n",
    "            rt.update({src:qobj(list(batch_df[src]))})\n",
    "        return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset: TaiChiDataset, quantify_dict: Dict[str, Quantify]):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "        self.collate = TaiChiCollate(quantify_dict)\n",
    "        \n",
    "    def configure(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = True,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):  \n",
    "        self.train_ds, self.val_ds = self.dataset.split(valid_ratio)\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.num_workers=num_workers\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        self.train_dl = self.train_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.train_dl.collate_fn = self.collate\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.val_dl = self.val_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.val_dl.collate_fn = self.collate\n",
    "        return self.val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_datamodule(df, qdict, phase):\n",
    "    ds = TaiChiDataset(df)\n",
    "    datamodule = TaiChiDataModule(ds, qdict)\n",
    "    \n",
    "    def configure_setting(kwargs):\n",
    "        global phase\n",
    "        datamodule.configure(**kwargs)\n",
    "        phase['batch_level'] = kwargs\n",
    "    interact_intercept(datamodule.configure, configure_setting)\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009c0e5ad9d74f9ba3bb20b0dd2b9369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='valid_ratio', max=0.5, min=0.01, step=0.01), Dropdowâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule = execute_datamodule(bear_df, qdict, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(datamodule.train_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choose your model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"enrich\": [\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"image\",\n",
       "      \"kwargs\": {\n",
       "        \"convert\": \"RGB\",\n",
       "        \"size\": 224\n",
       "      },\n",
       "      \"enrich\": \"EnrichImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"label\",\n",
       "      \"kwargs\": {},\n",
       "      \"enrich\": \"ParentAsLabel\"\n",
       "    }\n",
       "  ],\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"image\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"mean_\": \"imagenet\",\n",
       "        \"std_\": \"imagenet\"\n",
       "      },\n",
       "      \"quantify\": \"QuantifyImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"label\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1\n",
       "      },\n",
       "      \"quantify\": \"QuantifyCategory\"\n",
       "    }\n",
       "  ],\n",
       "  \"batch_level\": {\n",
       "    \"valid_ratio\": 0.1,\n",
       "    \"batch_size\": 32,\n",
       "    \"shuffle\": true,\n",
       "    \"num_workers\": 0\n",
       "  },\n",
       "  \"x_models\": {\n",
       "    \"image\": {\n",
       "      \"model_name\": \"ImageConvEncoder\",\n",
       "      \"src\": \"image\",\n",
       "      \"kwargs\": {\n",
       "        \"name\": \"resnet18\"\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"y_models\": {\n",
       "    \"label\": {\n",
       "      \"model_name\": \"CategoryTop\",\n",
       "      \"src\": \"label\",\n",
       "      \"kwargs\": {}\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    resnet18, resnet34, resnet50, resnet101, resnet152,\n",
    "    resnext101_32x8d, resnext50_32x4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiCategoricalEmbedding(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,num_embeddings,\n",
    "#         embedding_dim: LIST([2,4,8,16,32,64,128,256,512,1024], default=64,)\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_OPTIONS = {\"resnet18\": resnet18,\n",
    "                  \"resnet34\": resnet34,\n",
    "                  \"resnet50\": resnet50,\n",
    "                  \"resnet101\": resnet101,\n",
    "                  \"resnet152\": resnet152,\n",
    "                  \"resnext101_32x8d\": resnext101_32x8d,\n",
    "                  \"resnext50_32x4d\": resnext50_32x4d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidJoint1d(nn.Module):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "    \n",
    "    def forward(self, data):\n",
    "        tensors = list(data[key] for key in self.keys)\n",
    "        return torch.cat(tensors,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryModel(nn.Module):\n",
    "    is_entry = True\n",
    "    \n",
    "class Empty(EntryModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_features=1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls,\n",
    "        quantify):\n",
    "        return cls()\n",
    "\n",
    "class ImageConvEncoder(EntryModel):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.name = \"cnn\"\n",
    "        self.output_shape = (BATCH_SIZE, model.fc.in_features)\n",
    "        self.out_features = model.fc.in_features\n",
    "        model.fc = Empty()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"ComputerVisionEncoder: {self.name}\n",
    "        Outputs shape:{self.output_shape}\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: LIST(options=list(\n",
    "            RESNET_OPTIONS.keys()), default=\"resnet18\"),\n",
    "    ):\n",
    "        model = RESNET_OPTIONS[name](pretrained=True, progress=True,)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        return obj\n",
    "\n",
    "\n",
    "class CategoryEncoder(EntryModel):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Embedding(\n",
    "            num_embeddings,\n",
    "            embedding_dim)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        return self.model(idx)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        quantify,\n",
    "        embedding_dim: LIST(\n",
    "            options=[4, 8, 16, 32, 64, 128, 256, 512], default=128) = 128):\n",
    "        num_embeddings = len(quantify.category)\n",
    "        obj = CategoryEncoder(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        obj.out_features = out_features\n",
    "        return obj\n",
    "\n",
    "\n",
    "class TransformerEncoder(EntryModel):\n",
    "    \"\"\"\n",
    "    A model part to encode sequnce data in to vectors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, encoder_mode: BOOL(default=True) = True,):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.encoder_mode = encoder_mode\n",
    "\n",
    "    def forward(self, kwargs):\n",
    "        outputs = self.model(**kwargs)\n",
    "        if self.encoder_mode:\n",
    "            # output vector\n",
    "            return outputs.logits*kwargs['attention_mask'].mean(1)\n",
    "        return outputs\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: STR(default=\"bert-base-uncased\") = 'bert-base-cncased',\n",
    "        encoder_mode: BOOL(default=True) = True,\n",
    "    ):\n",
    "        from transformer import AutoModel\n",
    "        model = AutoModel.from_pretrained(name)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        obj.encoder_mode = encoder_mode\n",
    "        if encoder_mode:\n",
    "            obj.out_features= model.config.hidden_size\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = ImageConvEncoder.from_quantify(0,name=\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputerVisionEncoder: resnet18\n",
       "        Outputs shape:(<class '__main__.BATCH_SIZE'>, 512)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vectors = entry(data['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExitModel(nn.Module):\n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        return {\"loss\": loss, \"y_\": y_}\n",
    "    \n",
    "class CategoryTop(ExitModel):\n",
    "    prefer = \"CrossEntropyLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Softmax(dim=-1)\n",
    "        self.crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "class MultiCategoryTop(ExitModel):\n",
    "    prefer = \"BCEWithLogitsLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        return {\"loss\": loss, \"y_\": self.activation(y_)}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "\n",
    "class RegressionTop(ExitModel):\n",
    "    prefer = \"MSELoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.crit = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = 1\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntireModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTIFY_2_ENTRY_MAP = dict({\n",
    "    QuantifyImage:[\n",
    "        ImageConvEncoder,\n",
    "    ],\n",
    "    QuantifyCategory:[\n",
    "        CategoryEncoder,\n",
    "    ],\n",
    "    QuantifyText:[\n",
    "        TransformerEncoder,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        Empty,\n",
    "    ],\n",
    "})\n",
    "ENTRY_ALL = dict(\n",
    "    ImageConvEncoder=ImageConvEncoder,\n",
    "    CategoryEncoder=CategoryEncoder,\n",
    "    TransformerEncoder=TransformerEncoder,\n",
    "    Empty=Empty,\n",
    ")\n",
    "\n",
    "QUANTIFY_2_EXIT_MAP = dict({\n",
    "    QuantifyCategory:[\n",
    "        CategoryTop,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        RegressionTop,\n",
    "    ],\n",
    "})\n",
    "EXIT_ALL = dict(\n",
    "    CategoryTop=CategoryTop,\n",
    "    RegressionTop=RegressionTop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_models(quantify, cls_options, model_conf:str='x_models'):\n",
    "    def config_model(ModelClass=cls_options):\n",
    "        def starting_cls(kwargs):\n",
    "            global phase\n",
    "            if model_conf in phase:\n",
    "                models = phase[model_conf]\n",
    "            else:\n",
    "                models = dict()\n",
    "            models[quantify.src] = dict(\n",
    "            model_name=ModelClass.__name__,\n",
    "            src=quantify.src,\n",
    "            kwargs=kwargs,\n",
    "            )\n",
    "            phase[model_conf] = models\n",
    "        ia = InteractiveAnnotations(\n",
    "            ModelClass.from_quantify,\n",
    "            description=\"Okay\",\n",
    "            icon='rocket',\n",
    "            button_style='success')\n",
    "            \n",
    "        ia.register_callback(starting_cls)\n",
    "        display(ia.vbox)\n",
    "    inter = interact_manual(config_model)\n",
    "    reconfig_manual_interact(\n",
    "        inter.widget,\n",
    "        description=\"Yes!\", icon=\"cube\", button_style='info')\n",
    "    return inter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(quantify_dict: Dict[str, Quantify]):\n",
    "    global phase\n",
    "    x_models = dict()\n",
    "    y_models = dict()\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x:\n",
    "            entry_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_ENTRY_MAP.get(quantify.__class__))\n",
    "\n",
    "            if entry_cls_options is None:\n",
    "                print(f\"We do not support {quantify.__class__} as X data\")\n",
    "                continue\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-primary'>Choose Model For X Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, entry_cls_options, \"x_models\")\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x == False:\n",
    "            exit_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_EXIT_MAP.get(quantify.__class__))\n",
    "            if entry_cls_options is None:\n",
    "                print(f\"We do not support {quantify.__class__} as Y data\")\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-danger'>Choose Model For Y Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, exit_cls_options, \"y_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235e45da00f04781ae7f538607a36e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-primary'>Choose Model For X Column:\\n            <strong>image</stroâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b735356fe164f12b91381e43ac684e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'ImageConvEncoder': <class '__main__.ImageCoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862e18cf759044f0a0f9476aef9b3f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-danger'>Choose Model For Y Column:\\n            <strong>label</stronâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c2f0d5ffd848d396c839ae6f0a35a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'CategoryTop': <class '__main__.CategoryTop'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_model(qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phase:{\n",
       "  \"enrich\": [\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"image\",\n",
       "      \"kwargs\": {\n",
       "        \"convert\": \"RGB\",\n",
       "        \"size\": 224\n",
       "      },\n",
       "      \"enrich\": \"EnrichImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"path\",\n",
       "      \"dst\": \"label\",\n",
       "      \"kwargs\": {},\n",
       "      \"enrich\": \"ParentAsLabel\"\n",
       "    }\n",
       "  ],\n",
       "  \"quantify\": [\n",
       "    {\n",
       "      \"src\": \"image\",\n",
       "      \"x\": true,\n",
       "      \"kwargs\": {\n",
       "        \"mean_\": \"imagenet\",\n",
       "        \"std_\": \"imagenet\"\n",
       "      },\n",
       "      \"quantify\": \"QuantifyImage\"\n",
       "    },\n",
       "    {\n",
       "      \"src\": \"label\",\n",
       "      \"x\": false,\n",
       "      \"kwargs\": {\n",
       "        \"min_frequency\": 1\n",
       "      },\n",
       "      \"quantify\": \"QuantifyCategory\"\n",
       "    }\n",
       "  ],\n",
       "  \"batch_level\": {\n",
       "    \"valid_ratio\": 0.1,\n",
       "    \"batch_size\": 32,\n",
       "    \"shuffle\": true,\n",
       "    \"num_workers\": 0\n",
       "  },\n",
       "  \"x_models\": {\n",
       "    \"image\": {\n",
       "      \"model_name\": \"ImageConvEncoder\",\n",
       "      \"src\": \"image\",\n",
       "      \"kwargs\": {\n",
       "        \"name\": \"resnet18\"\n",
       "      }\n",
       "    }\n",
       "  },\n",
       "  \"y_models\": {\n",
       "    \"label\": {\n",
       "      \"model_name\": \"CategoryTop\",\n",
       "      \"src\": \"label\",\n",
       "      \"kwargs\": {}\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryDict(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        model_dict = nn.ModuleDict()\n",
    "        for src, model_cfg in phase['x_models'].items():\n",
    "            quantify = qdict[src]\n",
    "            model_cls = ENTRY_ALL[model_cfg['model_name']]\n",
    "            model_kwargs = model_cfg['kwargs']\n",
    "            model = model_cls.from_quantify(quantify, **model_kwargs)\n",
    "            model_dict[src] = model\n",
    "\n",
    "        self.out_features = sum(\n",
    "            list(model.out_features for src, model in model_dict.items()))\n",
    "        self.model_dict = model_dict\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for src, model in self.model_dict.items():\n",
    "            src_input = inputs[src]\n",
    "            outputs.append(model(src_input))\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_dict = EntryDict(phase, qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_ = entry_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssembledModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel],\n",
    "        entry_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6], default=1e-4)=1e-4,\n",
    "        exit_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, ], default=1e-3)=1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.entry_lr = entry_lr\n",
    "        self.exit_lr = exit_lr\n",
    "        self.entry_dict = EntryDict(phase, qdict)\n",
    "        exit_cfg = list(phase['y_models'].values())[0]\n",
    "        \n",
    "        self.exit_src = exit_cfg['src']\n",
    "        self.exit_kwargs = exit_cfg['kwargs']\n",
    "        exit_cls = EXIT_ALL[exit_cfg['model_name']]\n",
    "        \n",
    "        exit_quantify = qdict[self.exit_src]\n",
    "        \n",
    "        self.exit_part = exit_cls.from_quantify(\n",
    "            exit_quantify,self.entry_dict, **self.exit_kwargs)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part(vec)\n",
    "    \n",
    "    def loss_step(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part.loss_step(vec, inputs[self.exit_src])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            self.log(f\"trn_{k}\", v)\n",
    "        return rt['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            self.log(f\"val_{k}\", v)\n",
    "        return rt['loss']\n",
    "    \n",
    "    def configure_optimizers(self,):\n",
    "        param_groups = [\n",
    "            {\"params\":self.entry_dict.parameters(), \"lr\":self.entry_lr},\n",
    "            {\"params\":self.exit_part.parameters(), \"lr\":self.exit_lr},\n",
    "        ]\n",
    "        return torch.optim(param_groups)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(phase, qdict):\n",
    "    if \"y_models\" in phase:\n",
    "        y_models = phase[\"y_models\"]\n",
    "        if len(y_models)>1:\n",
    "            raise ValueError(\"Multiple targets are not supported by now\")\n",
    "        else:\n",
    "            return AssembledModel(phase, qdict)\n",
    "    else:\n",
    "        raise ValueError(\"phase must contain 'y_models' configuration for now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = create_model(phase, qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    final_model.loss_step(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.074px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
